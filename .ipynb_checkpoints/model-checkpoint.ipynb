{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To unzip files and read csv log file\n",
    "import os\n",
    "from zipfile import ZipFile\n",
    "import csv\n",
    "\n",
    "# to split, shuffle training and validation data\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# For Generators\n",
    "import cv2\n",
    "import numpy as np\n",
    "import sklearn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# For CNN\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Flatten, Activation, Dropout\n",
    "from keras.layers import Lambda, Cropping2D, Conv2D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "zipDir = './data.zip'\n",
    "logFile = './data/data/driving_log.csv'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "def uncompress_features_labels(dir,name):\n",
    "    if(os.path.isdir(name)):\n",
    "        print('Data extracted')\n",
    "    else:\n",
    "        with ZipFile(dir) as zipf:\n",
    "            zipf.extractall('data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data extracted\n"
     ]
    }
   ],
   "source": [
    "uncompress_features_labels(zipDir, 'data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples = [] #simple array to append all the entries present in the .csv file\n",
    "with open(logFile) as csvfile: #currently after extracting the file is present in this path\n",
    "    reader = csv.reader(csvfile)\n",
    "    next(reader, None) #this is necessary to skip the first record as it contains the headings\n",
    "    for line in reader:\n",
    "        samples.append(line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_samples, validation_samples = train_test_split(samples,test_size=0.15) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "53.359375"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(samples, batch_size=128):\n",
    "    num_samples = len(samples)\n",
    "   \n",
    "    while 1: \n",
    "        shuffle(samples) #shuffling the total images\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            \n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "\n",
    "            images = []\n",
    "            angles = []\n",
    "            for batch_sample in batch_samples:\n",
    "                    for i in range(0,3): #we are taking 3 images, first one is center, second is left and third is right\n",
    "                        \n",
    "                        name = './data/data/IMG/'+batch_sample[i].split('/')[-1]\n",
    "                        center_image = cv2.cvtColor(cv2.imread(name), cv2.COLOR_BGR2RGB) #since CV2 reads an image in BGR we need to convert it to RGB since in drive.py it is RGB\n",
    "                        center_angle = float(batch_sample[3]) #getting the steering angle measurement\n",
    "                        images.append(center_image)\n",
    "                        \n",
    "                        # introducing correction for left and right images\n",
    "                        # if image is in left we increase the steering angle by 0.2\n",
    "                        # if image is in right we decrease the steering angle by 0.2\n",
    "                        \n",
    "                        if(i==0):\n",
    "                            angles.append(center_angle)\n",
    "                        elif(i==1):\n",
    "                            angles.append(center_angle+0.2)\n",
    "                        elif(i==2):\n",
    "                            angles.append(center_angle-0.2)\n",
    "                        \n",
    "                        # Code for Augmentation of data.\n",
    "                        # We take the image and just flip it and negate the measurement\n",
    "                        \n",
    "                        images.append(cv2.flip(center_image,1))\n",
    "                        if(i==0):\n",
    "                            angles.append(center_angle*-1)\n",
    "                        elif(i==1):\n",
    "                            angles.append((center_angle+0.2)*-1)\n",
    "                        elif(i==2):\n",
    "                            angles.append((center_angle-0.2)*-1)\n",
    "                        #here we got 6 images from one image    \n",
    "                        \n",
    "        \n",
    "            X_train = np.array(images)\n",
    "            y_train = np.array(angles)\n",
    "            \n",
    "            yield sklearn.utils.shuffle(X_train, y_train) #here we do not hold the values of X_train and y_train instead we yield the values which means we hold until the generator is running"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile and train the model using the generator function\n",
    "train_generator = generator(train_samples, batch_size=128)\n",
    "validation_generator = generator(validation_samples, batch_size=128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\patil\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:61: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "C:\\Users\\patil\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\ipykernel_launcher.py:61: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., steps_per_epoch=53.359375, validation_data=<generator..., validation_steps=1260, verbose=1, epochs=1)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "54/53 [==============================] - 801s 15s/step - loss: 0.0238 - val_loss: 0.0188\n",
      "Done! Model Saved!\n",
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lambda_7 (Lambda)            (None, 160, 320, 3)       0         \n",
      "_________________________________________________________________\n",
      "cropping2d_6 (Cropping2D)    (None, 65, 320, 3)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_26 (Conv2D)           (None, 31, 158, 24)       1824      \n",
      "_________________________________________________________________\n",
      "activation_41 (Activation)   (None, 31, 158, 24)       0         \n",
      "_________________________________________________________________\n",
      "conv2d_27 (Conv2D)           (None, 14, 77, 36)        21636     \n",
      "_________________________________________________________________\n",
      "activation_42 (Activation)   (None, 14, 77, 36)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_28 (Conv2D)           (None, 5, 37, 48)         43248     \n",
      "_________________________________________________________________\n",
      "activation_43 (Activation)   (None, 5, 37, 48)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_29 (Conv2D)           (None, 3, 35, 64)         27712     \n",
      "_________________________________________________________________\n",
      "activation_44 (Activation)   (None, 3, 35, 64)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_30 (Conv2D)           (None, 1, 33, 64)         36928     \n",
      "_________________________________________________________________\n",
      "activation_45 (Activation)   (None, 1, 33, 64)         0         \n",
      "_________________________________________________________________\n",
      "flatten_6 (Flatten)          (None, 2112)              0         \n",
      "_________________________________________________________________\n",
      "dense_21 (Dense)             (None, 100)               211300    \n",
      "_________________________________________________________________\n",
      "activation_46 (Activation)   (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dropout_6 (Dropout)          (None, 100)               0         \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 50)                5050      \n",
      "_________________________________________________________________\n",
      "activation_47 (Activation)   (None, 50)                0         \n",
      "_________________________________________________________________\n",
      "dense_23 (Dense)             (None, 10)                510       \n",
      "_________________________________________________________________\n",
      "activation_48 (Activation)   (None, 10)                0         \n",
      "_________________________________________________________________\n",
      "dense_24 (Dense)             (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 348,219\n",
      "Trainable params: 348,219\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Sequential()\n",
    "\n",
    "# Preprocess incoming data, centered around zero with small standard deviation \n",
    "model.add(Lambda(lambda x: (x / 255.0) - 0.5, input_shape=(160,320,3)))\n",
    "\n",
    "# trim image to only see section with road\n",
    "model.add(Cropping2D(cropping=((70,25),(0,0))))           \n",
    "\n",
    "#layer 1- Convolution, no of filters- 24, filter size= 5x5, stride= 2x2\n",
    "model.add(Conv2D(24, (5, 5), strides=(2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#layer 2- Convolution, no of filters- 36, filter size= 5x5, stride= 2x2\n",
    "model.add(Conv2D(36, (5, 5), strides=(2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#layer 3- Convolution, no of filters- 48, filter size= 5x5, stride= 2x2\n",
    "model.add(Conv2D(48, (5, 5), strides=(2, 2)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#layer 4- Convolution, no of filters- 64, filter size= 3x3, stride= 1x1\n",
    "model.add(Conv2D(64, (3,3)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#layer 5- Convolution, no of filters- 64, filter size= 3x3, stride= 1x1\n",
    "model.add(Conv2D(64, (3,3)))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#flatten image from 2D to side by side\n",
    "model.add(Flatten())\n",
    "\n",
    "#layer 6- fully connected layer 1\n",
    "model.add(Dense(100))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#Adding a dropout layer to avoid overfitting. Here we are have given the dropout rate as 25% after first fully connected layer\n",
    "model.add(Dropout(0.25))\n",
    "\n",
    "#layer 7- fully connected layer 1\n",
    "model.add(Dense(50))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "\n",
    "#layer 8- fully connected layer 1\n",
    "model.add(Dense(10))\n",
    "model.add(Activation('relu'))\n",
    "\n",
    "#layer 9- fully connected layer 1\n",
    "model.add(Dense(1)) #here the final layer will contain one value as this is a regression problem and not classification\n",
    "\n",
    "\n",
    "# the output is the steering angle\n",
    "# using mean squared error loss function is the right choice for this regression problem\n",
    "# adam optimizer is used here\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "\n",
    "\n",
    "#fit generator is used here as the number of images are generated by the generator\n",
    "# no of epochs : 5\n",
    "\n",
    "model.fit_generator(train_generator, steps_per_epoch=len(train_samples)/128, validation_data=validation_generator, validation_steps=1260, nb_epoch=1, verbose=1)\n",
    "\n",
    "#saving model\n",
    "model.save_weights('model')\n",
    "\n",
    "print('Done! Model Saved!')\n",
    "\n",
    "# keras method to print the model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'optimizers' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-27-8b87a2220892>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTFOptimizer\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'optimizers' is not defined"
     ]
    }
   ],
   "source": [
    "optimizers.TFOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'keras.optimizers' has no attribute 'TFOptimizer'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-837839840332>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msave\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'test'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\network.py\u001b[0m in \u001b[0;36msave\u001b[1;34m(self, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[0;32m   1150\u001b[0m             \u001b[1;32mraise\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[1;33m.\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0msave_model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1152\u001b[1;33m         \u001b[0msave_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1153\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1154\u001b[0m     \u001b[1;33m@\u001b[0m\u001b[0msaving\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mallow_write_to_gcs\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\saving.py\u001b[0m in \u001b[0;36msave_wrapper\u001b[1;34m(obj, filepath, overwrite, *args, **kwargs)\u001b[0m\n\u001b[0;32m    447\u001b[0m                 \u001b[0mos\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mremove\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp_filepath\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    448\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 449\u001b[1;33m             \u001b[0msave_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moverwrite\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    450\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    451\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0msave_wrapper\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\saving.py\u001b[0m in \u001b[0;36msave_model\u001b[1;34m(model, filepath, overwrite, include_optimizer)\u001b[0m\n\u001b[0;32m    539\u001b[0m                 \u001b[1;32mreturn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    540\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mH5Dict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'w'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 541\u001b[1;33m             \u001b[0m_serialize_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mh5dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minclude_optimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    542\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'write'\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcallable\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilepath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    543\u001b[0m         \u001b[1;31m# write as binary stream\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\saving.py\u001b[0m in \u001b[0;36m_serialize_model\u001b[1;34m(model, h5dict, include_optimizer)\u001b[0m\n\u001b[0;32m    161\u001b[0m             \u001b[0mlayer_group\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mval\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    162\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0minclude_optimizer\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 163\u001b[1;33m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptimizers\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTFOptimizer\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    164\u001b[0m             warnings.warn(\n\u001b[0;32m    165\u001b[0m                 \u001b[1;34m'TensorFlow optimizers do not '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'keras.optimizers' has no attribute 'TFOptimizer'"
     ]
    }
   ],
   "source": [
    "model.save('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TensorFlow-GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
